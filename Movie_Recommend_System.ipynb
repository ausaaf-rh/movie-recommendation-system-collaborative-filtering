{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f86538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import zipfile\n",
    "import urllib.request\n",
    "import warnings\n",
    "from collections import defaultdict\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# -------------------- Config --------------------\n",
    "DATA_DIR = \"data/ml-100k\"\n",
    "ZIP_URL = \"https://files.grouplens.org/datasets/movielens/ml-100k.zip\"\n",
    "RATINGS_FILE = os.path.join(DATA_DIR, \"u.data\")\n",
    "ITEMS_FILE = os.path.join(DATA_DIR, \"u.item\")\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# -------------------- Utilities --------------------\n",
    "def download_ml100k_if_needed():\n",
    "    \"\"\"Download and extract MovieLens 100k if not present.\"\"\"\n",
    "    if os.path.exists(RATINGS_FILE) and os.path.exists(ITEMS_FILE):\n",
    "        print(\"Dataset already present:\", DATA_DIR)\n",
    "        return\n",
    "    os.makedirs(\"data\", exist_ok=True)\n",
    "    print(\"Downloading MovieLens 100K ...\")\n",
    "    try:\n",
    "        with urllib.request.urlopen(ZIP_URL, timeout=60) as resp:\n",
    "            data = resp.read()\n",
    "        with zipfile.ZipFile(io.BytesIO(data)) as zf:\n",
    "            zf.extractall(\"data\")\n",
    "        if not (os.path.exists(RATINGS_FILE) and os.path.exists(ITEMS_FILE)):\n",
    "            raise FileNotFoundError(\"Dataset not found after extraction.\")\n",
    "        print(\"Downloaded and extracted to:\", DATA_DIR)\n",
    "    except Exception as e:\n",
    "        msg = (\n",
    "            \"Automatic download failed. Please download ml-100k.zip manually from:\\n\"\n",
    "            \"https://grouplens.org/datasets/movielens/100k/\\n\"\n",
    "            \"and unzip into ./data/ml-100k/\"\n",
    "        )\n",
    "        raise RuntimeError(msg) from e\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"Return ratings_df, items_df\"\"\"\n",
    "    cols = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "    ratings = pd.read_csv(RATINGS_FILE, sep=\"\\t\", names=cols, engine=\"python\")\n",
    "    items = pd.read_csv(ITEMS_FILE, sep=\"|\", header=None, encoding=\"latin-1\")\n",
    "    items = items[[0,1]]\n",
    "    items.columns = [\"item_id\", \"title\"]\n",
    "    items[\"item_id\"] = items[\"item_id\"].astype(int)\n",
    "    return ratings, items\n",
    "\n",
    "# -------------------- EDA --------------------\n",
    "def quick_eda(ratings, items):\n",
    "    print(\"Ratings shape:\", ratings.shape)\n",
    "    print(\"Unique users:\", ratings['user_id'].nunique(), \"Unique items:\", ratings['item_id'].nunique())\n",
    "    print(\"Rating counts:\")\n",
    "    print(ratings['rating'].value_counts().sort_index())\n",
    "\n",
    "    plt.figure(figsize=(8,3))\n",
    "    sns.countplot(x='rating', data=ratings, order=sorted(ratings['rating'].unique()))\n",
    "    plt.title(\"Rating distribution\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    pop = ratings.groupby('item_id').agg(count=('rating','size'), avg=('rating','mean')).reset_index()\n",
    "    top10 = pop.sort_values(['count','avg'], ascending=[False,False]).head(10).merge(items, on='item_id')\n",
    "    print(\"\\nTop-10 most rated movies (popularity baseline):\")\n",
    "    display_cols = top10[['item_id','title','count','avg']]\n",
    "    print(display_cols.to_string(index=False))\n",
    "    return top10\n",
    "\n",
    "# -------------------- Build interaction matrices --------------------\n",
    "def build_user_item_matrix(ratings_df, fillna=0):\n",
    "    \"\"\"\n",
    "    Returns user-item pivot DataFrame (users as rows, items as columns).\n",
    "    Missing entries filled with `fillna` (default 0).\n",
    "    \"\"\"\n",
    "    pivot = ratings_df.pivot(index='user_id', columns='item_id', values='rating').fillna(fillna)\n",
    "    return pivot\n",
    "\n",
    "# -------------------- Item-item similarity (cosine) --------------------\n",
    "def compute_item_similarity(pivot_df):\n",
    "    \"\"\"\n",
    "    pivot_df: users x items (DataFrame)\n",
    "    returns: item_similarity matrix (numpy array), item_id_list (columns of pivot_df)\n",
    "    \"\"\"\n",
    "    item_matrix = pivot_df.T.values  # items x users\n",
    "    # cosine similarity between items\n",
    "    sim = cosine_similarity(item_matrix)  # shape: items x items\n",
    "    return sim, list(pivot_df.columns)\n",
    "\n",
    "# -------------------- Recommendation function --------------------\n",
    "def recommend_items_for_user_knn(user_id, pivot_df, item_sim, item_ids, topn=10):\n",
    "    \"\"\"\n",
    "    Returns DataFrame with top-n recommended item_ids (no titles).\n",
    "    - Excludes items the user already rated in pivot_df.\n",
    "    - Uses weighted sum of item similarities x user_ratings.\n",
    "    \"\"\"\n",
    "    if user_id not in pivot_df.index:\n",
    "        raise ValueError(f\"User {user_id} not in pivot matrix (cold-start).\")\n",
    "\n",
    "    user_ratings = pivot_df.loc[user_id].values  # length = n_items\n",
    "    # indices of items user rated > 0\n",
    "    rated_indices = np.where(user_ratings > 0)[0]\n",
    "    if len(rated_indices) == 0:\n",
    "        # cold-start within known users -> return top popular by count (fallback should be applied externally)\n",
    "        return []\n",
    "\n",
    "    # score for each item = sum over rated items (similarity * rating)\n",
    "    scores = np.zeros(len(item_ids), dtype=float)\n",
    "    for idx in rated_indices:\n",
    "        sim_row = item_sim[:, idx]\n",
    "        scores += sim_row * user_ratings[idx]\n",
    "\n",
    "    # set scores of already-rated items to -inf to avoid recommending them\n",
    "    scores[rated_indices] = -np.inf\n",
    "\n",
    "    # top indices\n",
    "    top_indices = np.argsort(scores)[-topn:][::-1]\n",
    "    top_item_ids = [item_ids[i] for i in top_indices]\n",
    "    top_scores = [scores[i] for i in top_indices]\n",
    "    return list(zip(top_item_ids, top_scores))\n",
    "\n",
    "# -------------------- Evaluation: Precision@K / Recall@K --------------------\n",
    "def evaluate_precision_recall(ratings_df, pivot_df, item_sim, item_ids, k=10, test_df=None):\n",
    "    \"\"\"\n",
    "    Evaluate recommender using test_df (user,item) pairs.\n",
    "    We compute Precision@K and Recall@K averaged across users who have at least one test item\n",
    "    and at least one train item.\n",
    "    - test_df: DataFrame with columns user_id,item_id (if None, use a random 20% holdout)\n",
    "    \"\"\"\n",
    "    if test_df is None:\n",
    "        # default: simple random holdout 20% of ratings, stratified by user if possible\n",
    "        train_df, test_df = train_test_split(ratings_df, test_size=0.2, random_state=RANDOM_STATE)\n",
    "    else:\n",
    "        train_df = ratings_df.drop(test_df.index, errors='ignore')  # fallback\n",
    "\n",
    "    # We will assume pivot_df corresponds to the train split; caller must ensure that.\n",
    "    user_groups = test_df.groupby('user_id')['item_id'].apply(set).to_dict()\n",
    "    precisions = []\n",
    "    recalls = []\n",
    "    n_users_evaluated = 0\n",
    "\n",
    "    for user, true_items in user_groups.items():\n",
    "        if user not in pivot_df.index:\n",
    "            continue  # user cold-start -> skip (or handle separately)\n",
    "        # generate recommendations\n",
    "        recs = recommend_items_for_user_knn(user, pivot_df, item_sim, item_ids, topn=k)\n",
    "        if not recs:\n",
    "            continue\n",
    "        rec_item_ids = [iid for iid, _ in recs]\n",
    "        # compute metrics\n",
    "        hit_count = len(set(rec_item_ids) & set(true_items))\n",
    "        prec = hit_count / k\n",
    "        rec = hit_count / len(true_items) if len(true_items) > 0 else 0.0\n",
    "        precisions.append(prec)\n",
    "        recalls.append(rec)\n",
    "        n_users_evaluated += 1\n",
    "\n",
    "    if n_users_evaluated == 0:\n",
    "        return 0.0, 0.0, 0\n",
    "\n",
    "    return float(np.mean(precisions)), float(np.mean(recalls)), n_users_evaluated\n",
    "\n",
    "# -------------------- Main runnable flow --------------------\n",
    "def main_run(example_user=1, topn=10, test_size=0.2):\n",
    "    # 1) download if needed + load\n",
    "    download_ml100k_if_needed()\n",
    "    ratings, items = load_data()\n",
    "\n",
    "    # 2) quick EDA\n",
    "    top10 = quick_eda(ratings, items)\n",
    "\n",
    "    # 3) train/test split (random holdout)\n",
    "    train_df, test_df = train_test_split(ratings, test_size=test_size, random_state=RANDOM_STATE)\n",
    "    print(f\"\\nTrain shape: {train_df.shape}, Test shape: {test_df.shape}\")\n",
    "\n",
    "    # 4) build pivot from train only\n",
    "    pivot_train = build_user_item_matrix(train_df, fillna=0)\n",
    "\n",
    "    # 5) compute item similarity from train pivot\n",
    "    item_sim_matrix, item_id_list = compute_item_similarity(pivot_train)\n",
    "    print(\"Computed item-item similarity matrix.\")\n",
    "\n",
    "    # 6) popularity baseline for cold-start fallback\n",
    "    pop_counts = train_df.groupby('item_id').size().sort_values(ascending=False)\n",
    "    pop_top_items = pop_counts.index[:topn].tolist()\n",
    "\n",
    "    # 7) evaluate on test set\n",
    "    p_at_10, r_at_10, users_eval = evaluate_precision_recall(train_df, pivot_train, item_sim_matrix, item_id_list, k=topn, test_df=test_df)\n",
    "    print(f\"\\nEvaluation (Item-KNN) — Precision@{topn}: {p_at_10:.4f}, Recall@{topn}: {r_at_10:.4f} (users_eval={users_eval})\")\n",
    "\n",
    "    # 8) produce recommendations for example_user\n",
    "    print(f\"\\nTop-{topn} recommendations for user {example_user}:\")\n",
    "    if example_user not in pivot_train.index:\n",
    "        print(\"User not in train (cold-start). Returning popularity baseline items.\")\n",
    "        recs = [(iid, None) for iid in pop_top_items]\n",
    "    else:\n",
    "        recs = recommend_items_for_user_knn(example_user, pivot_train, item_sim_matrix, item_id_list, topn=topn)\n",
    "\n",
    "    # map ids -> titles and display\n",
    "    recs_df = pd.DataFrame(recs, columns=['item_id','score'])\n",
    "    recs_df = recs_df.merge(items, on='item_id', how='left')\n",
    "    # order by score (if score None, keep popularity order)\n",
    "    recs_df['score'] = recs_df['score'].fillna(-1.0)\n",
    "    recs_df = recs_df.sort_values('score', ascending=False).reset_index(drop=True)\n",
    "    print(recs_df[['item_id','title','score']].to_string(index=False))\n",
    "\n",
    "    # 9) Also print popularity baseline top-10 titles\n",
    "    print(\"\\nPopularity baseline (top-10 most rated in train):\")\n",
    "    pop_df = pd.DataFrame({'item_id': pop_top_items}).merge(items, on='item_id')\n",
    "    print(pop_df[['item_id','title']].to_string(index=False))\n",
    "\n",
    "    # 10) return key objects for further use\n",
    "    return {\n",
    "        'train_df': train_df,\n",
    "        'test_df': test_df,\n",
    "        'pivot_train': pivot_train,\n",
    "        'item_sim_matrix': item_sim_matrix,\n",
    "        'item_id_list': item_id_list,\n",
    "        'recommendations_df': recs_df,\n",
    "        'popularity_top10': pop_df,\n",
    "        'metrics': {'precision@k': p_at_10, 'recall@k': r_at_10, 'users_evaluated': users_eval}\n",
    "    }\n",
    "\n",
    "# -------------------- Run script --------------------\n",
    "if __name__ == \"__main__\":\n",
    "    results = main_run(example_user=1, topn=10, test_size=0.2)\n",
    "\n",
    "    # Interactive system (add this to Cell 1)\n",
    "def get_user_recommendations(results):\n",
    "    try:\n",
    "        user_id = int(input(\"Enter User ID: \"))\n",
    "        n_recs = int(input(\"Number of recommendations (default 5): \") or \"5\")\n",
    "        \n",
    "        if user_id in results['pivot_train'].index:\n",
    "            recs = recommend_items_for_user_knn(\n",
    "                user_id, \n",
    "                results['pivot_train'], \n",
    "                results['item_sim_matrix'], \n",
    "                results['item_id_list'], \n",
    "                topn=n_recs\n",
    "            )\n",
    "            if recs:\n",
    "                _, items = load_data()\n",
    "                recs_df = pd.DataFrame(recs, columns=['item_id','score'])\n",
    "                recs_df = recs_df.merge(items, on='item_id')\n",
    "                print(f\"\\nRecommendations for User {user_id}:\")\n",
    "                print(recs_df[['title','score']].to_string(index=False))\n",
    "            else:\n",
    "                print(\"No recommendations found\")\n",
    "        else:\n",
    "            print(\"User not found in dataset\")\n",
    "    except:\n",
    "        print(\"Invalid input\")\n",
    "\n",
    "# Menu system\n",
    "if 'results' in locals():\n",
    "    while True:\n",
    "        print(\"\\n1. Get recommendations for user\")\n",
    "        print(\"2. Show system metrics\") \n",
    "        print(\"3. Exit\")\n",
    "        choice = input(\"Choice: \")\n",
    "        \n",
    "        if choice == \"1\":\n",
    "            get_user_recommendations(results)\n",
    "        elif choice == \"2\":\n",
    "            print(f\"Precision@10: {results['metrics']['precision@k']:.4f}\")\n",
    "            print(f\"Recall@10: {results['metrics']['recall@k']:.4f}\")\n",
    "        elif choice == \"3\":\n",
    "            break\n",
    "        else:\n",
    "            print(\"Invalid choice!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8ada745",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
